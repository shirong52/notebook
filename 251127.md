---


---

<h2 id="lazycall学习">1. Lazycall学习</h2>
<blockquote>
<p><a href="https://detectron.cn/en/latest/tutorials/lazyconfigs.html">延迟配置 - detectron2 0.6 文档 - detectron2 文档</a><br>
使用递归实例化，使用字典来描述对函数/类的调用</p>
</blockquote>
<p><strong>字典包括</strong>：<br>
(1) 一个“<em>target</em>”键，它包含可调用的路径，例如“module.submodule.class_name”。<br>
(2) 其他表示要传递给可调用的参数的键。参数本身可以使用递归实例化来定义。</p>
<p><strong>示例代码</strong>：</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>config <span class="token keyword">import</span> LazyCall <span class="token keyword">as</span> L
<span class="token keyword">from</span> my_app <span class="token keyword">import</span> Trainer<span class="token punctuation">,</span> Optimizer
cfg <span class="token operator">=</span> L<span class="token punctuation">(</span>Trainer<span class="token punctuation">)</span><span class="token punctuation">(</span>
  optimizer<span class="token operator">=</span>L<span class="token punctuation">(</span>Optimizer<span class="token punctuation">)</span><span class="token punctuation">(</span>
    lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    algo<span class="token operator">=</span><span class="token string">"SGD"</span>
  <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre>
<p>此时创建了<strong>字典</strong>：</p>
<pre class=" language-python"><code class="prism  language-python">cfg <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token string">"_target_"</span><span class="token punctuation">:</span> <span class="token string">"my_app.Trainer"</span><span class="token punctuation">,</span>
  <span class="token string">"optimizer"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
    <span class="token string">"_target_"</span><span class="token punctuation">:</span> <span class="token string">"my_app.Optimizer"</span><span class="token punctuation">,</span>
    <span class="token string">"lr"</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">"algo"</span><span class="token punctuation">:</span> <span class="token string">"SGD"</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>通过使用这样的字典来表示对象，一个通用的 <mark>instantiate 函数</mark>可以将它们转换为实际对象:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>config <span class="token keyword">import</span> instantiate
trainer <span class="token operator">=</span> instantiate<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span>
<span class="token comment"># equivalent to:</span>
<span class="token comment"># from my_app import Trainer, Optimizer</span>
<span class="token comment"># trainer = Trainer(optimizer=Optimizer(lr=0.01, algo="SGD"))</span>
</code></pre>
<h2 id="python分布式训练概述ddp">2. python分布式训练概述/DDP</h2>
<blockquote>
<p><a href="https://docs.pytorch.org/tutorials/beginner/dist_overview.html">PyTorch 分布式概述 — PyTorch 教程 2.9.0+cu128 文档 — PyTorch Distributed Overview — PyTorch Tutorials 2.9.0+cu128 documentation</a></p>
</blockquote>
<blockquote>
<p><a href="https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html">分布式数据并行入门 — PyTorch 教程 2.9.0+cu128 文档 — Getting Started with Distributed Data Parallel — PyTorch Tutorials 2.9.0+cu128 documentation</a></p>
</blockquote>
<p><strong>并行技术选取指南</strong></p>
<ol>
<li>如果模型能容纳在单个 GPU 上，但你想用多 GPU 轻松扩展训练规模，可以使用分布式数据并行（DDP）。</li>
<li>当你的模型无法安装在一块显卡上时，可以使用 FullyShardedDataParallel（FSDP2）。</li>
<li>如果 FSDP2 的缩放限制，可以使用张量并行（TP） 和/或流水线并行（PP）。</li>
</ol>
<p><strong>DDP</strong></p>

